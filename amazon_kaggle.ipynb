{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "165616e9-b80b-4b32-863d-52e03f0a6fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 22.0.3; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mdevice: cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from time import time\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import Counter\n",
    "import dill as pickle\n",
    "\n",
    "from plotly import graph_objects as go\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import fbeta_score, confusion_matrix\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms as T, models\n",
    "from torch.optim import Adam\n",
    "!pip install -q torchsummary --user\n",
    "from torchsummary import summary\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc20d83a-3b71-4a7f-b7e2-e355df86c59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(101)\n",
    "np.random.seed(101)\n",
    "torch.manual_seed(101);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60337e4f-d534-4e92-9ef6-caf1f329fa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ../input/planets-dataset/planet/planet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ff398e-a151-44cf-a98e-0468df763c74",
   "metadata": {},
   "source": [
    "#### Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0644ef1c-5d2e-4af1-ac72-159d5df8ad0e",
   "metadata": {},
   "source": [
    "##### Labels distribution\n",
    "###### Let's first load the training dataset and quantify the label distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb36d11c-82e7-4441-b560-740b72b11eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../input/planets-dataset/planet/planet/\"\n",
    "path_train = os.path.join(path, \"train-jpg\")\n",
    "path_test = os.path.join(path, \"test-jpg\")\n",
    "print(\n",
    "    f\"train files: {len(os.listdir(path_train))}, \"\n",
    "    f\"test files: {len(os.listdir(path_test))}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b7908f-fcd5-4f8c-84ef-c22e6259fba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_class = os.path.join(path, \"train_classes.csv\")\n",
    "df_class = pd.read_csv(path_class)\n",
    "print(df_class.shape)\n",
    "df_class.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6875ff12-c01e-424f-98a1-45375e68c362",
   "metadata": {},
   "source": [
    "###### Simple counter of individual label, by splitting them from tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0866eb51-bdfd-4957-8bfa-0bec456c4043",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class[\"list_tags\"] = df_class.tags.str.split(\" \")\n",
    "row_tags = df_class.list_tags.values\n",
    "tags = [tag for row in row_tags for tag in row]\n",
    "counter_tags = Counter(tags)\n",
    "df_tags = pd.DataFrame(\n",
    "    {\"tag\": counter_tags.keys(), \"total\": counter_tags.values()}\n",
    ").sort_values(\"total\")\n",
    "\n",
    "fig = px.bar(df_tags, x=\"total\", y=\"tag\", orientation=\"h\", \n",
    "             color=\"total\",\n",
    ")\n",
    "fig.update_layout(title=\"Class distribution\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9af931-5f30-43d9-bc48-35db562ccb85",
   "metadata": {},
   "source": [
    "###### As expected, some classes are largely representated whereas some are barely present in this dataset, in a Pareto distribution fashion. There is an important risk that our model doesn't learn the rare classes well or even to exclude them from the training data upon splitting between training and validating sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c066b35a-d913-4dfe-900e-0a5de0386f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "RARE_CLASSES = [\n",
    "    \"bare_ground\", \"selective_logging\", \"artisinal_mine\", \"blooming\", \"slash_burn\", \"blow_down\", \"conventional_mine\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecf2d31-045f-4c56-a4a3-5dac1362d055",
   "metadata": {},
   "source": [
    "#### Stratified KFold on Multilabel target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1ad577-ed37-4c81-98a6-7896d533f2a3",
   "metadata": {},
   "source": [
    "###### How to deal with class imbalance in a multiclass label scenario? Use a strategy similar to stratified cross-validation. We need to maintain class distribution accross all folds. Hat tips to Jessica Collins for the following solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbd9f75-1a8b-4b86-af6b-a06d839bfcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proba_mass_split(y, folds=5):\n",
    "\n",
    "    obs, classes = y.shape\n",
    "    dist = y.sum(axis=0).astype('float')\n",
    "    dist /= dist.sum()\n",
    "    idx_folds = []\n",
    "    dist_folds = np.zeros((folds, classes), dtype='float')\n",
    "    for _ in range(folds):\n",
    "        idx_folds.append([])\n",
    "    for i in range(obs):\n",
    "        if i < folds:\n",
    "            target_fold = i\n",
    "        else:\n",
    "            normed_folds = dist_folds.T / dist_folds.sum(axis=1)\n",
    "            how_off = normed_folds.T - dist\n",
    "            target_fold = np.argmin(np.dot((y[i] - .5).reshape(1, -1), how_off.T))\n",
    "        dist_folds[target_fold] += y[i]\n",
    "        idx_folds[target_fold].append(i)\n",
    "    \n",
    "    return idx_folds, np.array(dist_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b42275-7b0b-40b9-9c69-5b72fd5e310b",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_folds = 5\n",
    "\n",
    "encoder = MultiLabelBinarizer()\n",
    "ohe_tags = encoder.fit_transform(df_class.list_tags.values)\n",
    "idx_folds, dist_folds = proba_mass_split(ohe_tags, folds=N_folds)\n",
    "total_class = dist_folds.sum(axis=0)\n",
    "\n",
    "rows = []\n",
    "for idx, row in enumerate(dist_folds, 1):\n",
    "    for jdx, val in enumerate(row):\n",
    "        rows.append({\n",
    "            \"fold\": str(idx),\n",
    "            \"class\": encoder.classes_[jdx],\n",
    "            \"share\": val / total_class[jdx],\n",
    "            \"count\": val,\n",
    "        })\n",
    "\n",
    "df_fold = pd.DataFrame(rows)\n",
    "fig = px.bar(df_fold, x=\"class\", y=\"share\", text=\"count\", color=\"fold\")\n",
    "fig.update_layout(title=\"Label distribution accross folds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c119073b-30ca-42bf-9111-71fa8944eb06",
   "metadata": {},
   "source": [
    "###### This split method shows a consistent distribution of labels accross all folds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf8b4eb-3b30-4428-907a-1d2b7ed814c2",
   "metadata": {},
   "source": [
    "#### Class visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa1a7dd-9570-45d8-9e5b-14ecfc901e14",
   "metadata": {},
   "source": [
    "###### Let's now observe each label invidually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7ab4db-6c89-4c2e-ab8d-b749854d8ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tags = list(set(tags))\n",
    "N_tags = len(all_tags)\n",
    "fig, axes = plt.subplots(4, (N_tags//4)+1, figsize=(20, 20))\n",
    "for idx, tag in enumerate(all_tags):\n",
    "    filename = df_class.loc[df_class.tags.str.contains(tag)].image_name.values[0]\n",
    "    img = cv2.imread(os.path.join(path_train, filename+\".jpg\"))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    idx_col = idx // 4\n",
    "    idx_row = idx % 4\n",
    "    axes[idx_row][idx_col].set_title(tag)\n",
    "    axes[idx_row][idx_col].imshow(img)\n",
    "axes[1][-1].remove()\n",
    "axes[2][-1].remove()\n",
    "axes[3][-1].remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca8d467-2c22-45e1-87ea-e7e381dc7188",
   "metadata": {},
   "source": [
    "###### We can make few remarks here: Some labels like \"water\" or \"road\" are challenging to differenciate, Some rare labels like selecting logging and blooming are also hard to discriminate, and are barely visible at all, Strong correlations can be expected between labels like habitation, road and cultivations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcaff0e6-7042-483d-82db-af5056101434",
   "metadata": {},
   "source": [
    "#### T-SNE and dimension shrinking for visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5814caa3-f63f-4b9c-aa26-94fd26afa68e",
   "metadata": {},
   "source": [
    "###### T-SNE allows us to cluster our dataset by shrinking the image dimensions to only 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdb24bd-8406-4dc5-b7bf-ad0c99fd7460",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(path_file):\n",
    "    img = cv2.imread(path_file)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (100, 100), cv2.INTER_LINEAR).astype(float)\n",
    "    img = cv2.normalize(img, None, 0.0, 1.0, cv2.NORM_MINMAX)\n",
    "    img = img.reshape(1, -1)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7af2a4-8068-4949-949f-b1b45f4df0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = df_class.image_name.sample(600).values\n",
    "path_files = [os.path.join(path_train, filename+\".jpg\") for filename in filenames]\n",
    "X_train_sample = np.vstack([load_img(path_file) for path_file in path_files])\n",
    "X_train_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042dc7ec-d325-457a-a8c2-55a02177b0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(\n",
    "    n_components=2,\n",
    "    init=\"random\",\n",
    "    random_state=101,\n",
    "    method=\"barnes_hut\",\n",
    "    n_iter=500,\n",
    "    verbose=2,\n",
    ")\n",
    "X_embedded = tsne.fit_transform(X_train_sample)\n",
    "X_embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f625ca-2ee1-4b02-a9c6-6414195ab750",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_img(path_file, h, w):\n",
    "    img = cv2.imread(path_file)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (h*2, w*2), cv2.INTER_LINEAR)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38eeeb8-26f1-432f-8a6d-d8e217947398",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_img = 1000\n",
    "offset_img = 50\n",
    "h = w = int(offset_img / 2)\n",
    "\n",
    "X_scaled = (X_embedded - X_embedded.min(0)) / (X_embedded.max(0) - X_embedded.min(0))\n",
    "X_scaled = (X_scaled * size_img).astype(int)\n",
    "X_scaled = np.clip(X_scaled, offset_img, size_img-offset_img)\n",
    "\n",
    "img_tsne = np.ones((size_img+2*offset_img, size_img+2*offset_img, 3), dtype=np.uint8) * 255\n",
    "for idx in range(X_scaled.shape[0]):\n",
    "    x, y = X_scaled[idx][0], X_scaled[idx][1]\n",
    "    img = fetch_img(path_files[idx], h, w)\n",
    "    img_tsne[x-w:x+w, y-h:y+h, :] = img\n",
    "\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "plt.imshow(img_tsne);\n",
    "plt.axis(\"off\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa311b5-0433-4ddb-bc2e-6c6d674270f0",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fb93f5-fe11-4ed8-ab64-93e97fc6d789",
   "metadata": {},
   "source": [
    "##### Data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02249ee3-df2c-4f37-ba0b-e9febefc380e",
   "metadata": {},
   "source": [
    "###### Data augmentation is helpful to diversify our training dataset and build a more robust model. It is applied on each image for each batch, meaning that is doesn't increase the length of our training dataset per say, but it transforms each image randomly during execution time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1402a5-5f90-40de-8d28-215acb6498d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms():\n",
    "    transform_train = T.Compose([\n",
    "      T.ToPILImage(),\n",
    "      T.Resize(224),\n",
    "      T.RandomAffine(\n",
    "          degrees=(-90, 90),\n",
    "      ),\n",
    "      T.ToTensor(),\n",
    "      T.Normalize(\n",
    "          mean=[0.485, 0.456, 0.406],\n",
    "          std=[0.229, 0.224, 0.225],\n",
    "      )\n",
    "    ])\n",
    "    transform_val = T.Compose([\n",
    "      T.ToPILImage(),\n",
    "      T.Resize(224),\n",
    "      T.ToTensor(),\n",
    "      T.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225],\n",
    "      )\n",
    "    ])\n",
    "    return transform_train, transform_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410846ed-8f79-4e37-a2e4-58c91fd007d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AmazonDataset(Dataset):\n",
    "    def __init__(self, df, ohe_tags, transform, path):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.ohe_tags = ohe_tags\n",
    "        self.transform = transform\n",
    "        if isinstance(path, str):\n",
    "            self.paths = [path]\n",
    "        elif isinstance(path, (list, tuple)):\n",
    "            self.paths = path\n",
    "        else:\n",
    "            raise ValueError(f\"path type must be str, list or tuple, got {type(path)}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filename = self.df.iloc[idx].image_name + \".jpg\"\n",
    "        for path in self.paths:\n",
    "            if filename in os.listdir(path):\n",
    "                file_path = os.path.join(path, filename)\n",
    "                break\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"Can't fetch {filename} among {self.paths}\")\n",
    "        img = cv2.imread(file_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        label = self.ohe_tags[idx]\n",
    "        return img, label\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        imgs, labels = [], []\n",
    "        for row in batch:\n",
    "            img = torch.tensor(row[0])\n",
    "            img = img.permute(2, 0, 1)\n",
    "            img = self.transform(img)\n",
    "            label = row[1]\n",
    "            imgs.append(img[None])\n",
    "            labels.append(label)\n",
    "        imgs = torch.cat(imgs).float().to(device)\n",
    "        labels = torch.tensor(labels).float().to(device)\n",
    "        return imgs, labels\n",
    "\n",
    "    def load_img(self, idx, ax=None):\n",
    "        img, ohe_label = self[idx]\n",
    "        label = self.df.iloc[idx].tags\n",
    "        title = f\"{label} - {ohe_label}\"\n",
    "        if ax is None:\n",
    "            plt.imshow(img)\n",
    "            plt.title(title)\n",
    "        else:\n",
    "            ax.imshow(img)\n",
    "            ax.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75029c69-fe96-48f7-9a3d-68f6f82f51e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(df_train, df_val):\n",
    "\n",
    "    encoder = MultiLabelBinarizer()\n",
    "    ohe_tags_train = encoder.fit_transform(df_train.list_tags.values)\n",
    "    ohe_tags_val = encoder.transform(df_val.list_tags.values)\n",
    "\n",
    "    transform_train, transform_val = get_transforms()\n",
    "    ds_train = AmazonDataset(df_train, ohe_tags_train, transform_train, path=path_train)\n",
    "    ds_val = AmazonDataset(df_val, ohe_tags_val, transform_val, path=path_train)\n",
    "\n",
    "    dl_train = DataLoader(\n",
    "      ds_train,\n",
    "      batch_size=64,\n",
    "      shuffle=True,\n",
    "      collate_fn=ds_train.collate_fn\n",
    "    )\n",
    "    dl_val = DataLoader(\n",
    "      ds_val,\n",
    "      batch_size=64,\n",
    "      shuffle=True,\n",
    "      collate_fn=ds_val.collate_fn\n",
    "    )\n",
    "\n",
    "    return ds_train, ds_val, dl_train, dl_val, encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd72a8d8-96e2-4ace-a8ea-141e184e8274",
   "metadata": {},
   "source": [
    "###### Sanity check: we are expecting imgs to be a batch of our chosen batch size, with 3 channels and of chosen image dimensions. labels are also a batch of our chosen size with 17 different classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbde80d8-6849-4e70-b541-7bf2d3054636",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_class.iloc[idx_folds[0]]\n",
    "df_val = df_class.iloc[idx_folds[1]]\n",
    "\n",
    "ds_train, ds_val, dl_train, dl_val, encoder = get_data(df_train, df_val)\n",
    "\n",
    "imgs, labels = next(iter(dl_train))\n",
    "imgs.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2303ac48-ed08-4cb2-86ff-5c73b2a5fd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train.load_img(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7be58c-74dc-4182-996c-329575a643b2",
   "metadata": {},
   "source": [
    "#### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d980c7a-1d52-4c5a-bb1f-322c249d4299",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = models.resnet50(pretrained=True)\n",
    "    for param in model.parameters():\n",
    "        param.require_grad = False\n",
    "    model.avgpool = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "    model.fc = nn.Sequential(\n",
    "      nn.Flatten(),\n",
    "      nn.Linear(2048, 128), # 512 for resnet18 or 2048 for resnet 50\n",
    "      nn.ReLU(inplace=True),\n",
    "      nn.Dropout(.2),\n",
    "      nn.Linear(128, 17),\n",
    "      nn.Sigmoid()\n",
    "    )\n",
    "    optimizer = Adam(model.parameters(), lr=1e-4)\n",
    "    loss_fn = nn.BCELoss()\n",
    "\n",
    "    return model.to(device), optimizer, loss_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3bec8a-5b5b-4992-925f-5051c0f0344f",
   "metadata": {},
   "source": [
    "##### Callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523ac1da-a19d-40a7-9121-5aaef82582f9",
   "metadata": {},
   "source": [
    "###### We implement a scheduler to decrease learning rate upon stagnating validation loss, and also a early stopping callback to end training when no improvement on the validation loss are observed.\n",
    "\n",
    "https://debuggercafe.com/using-learning-rate-scheduler-and-early-stopping-with-pytorch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16b4751-34ab-4675-822e-ad0d8b70f4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LRScheduler():\n",
    "    \"\"\"\n",
    "    Learning rate scheduler. If the validation loss does not decrease for the \n",
    "    given number of `patience` epochs, then the learning rate will decrease by\n",
    "    by given `factor`.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, optimizer, patience=1, min_lr=1e-6, factor=0.5\n",
    "    ):\n",
    "        \"\"\"\n",
    "        new_lr = old_lr * factor\n",
    "\n",
    "        :param optimizer: the optimizer we are using\n",
    "        :param patience: how many epochs to wait before updating the lr\n",
    "        :param min_lr: least lr value to reduce to while updating\n",
    "        :param factor: factor by which the lr should be updated\n",
    "        \"\"\"\n",
    "        self.optimizer = optimizer\n",
    "        self.patience = patience\n",
    "        self.min_lr = min_lr\n",
    "        self.factor = factor\n",
    "\n",
    "        self.lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau( \n",
    "                self.optimizer,\n",
    "                mode='min',\n",
    "                patience=self.patience,\n",
    "                factor=self.factor,\n",
    "                min_lr=self.min_lr,\n",
    "                verbose=True\n",
    "            )\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        self.lr_scheduler.step(val_loss)\n",
    "\n",
    "\n",
    "class EarlyStopping():\n",
    "    \"\"\"\n",
    "    Early stopping to stop the training when the loss does not improve after\n",
    "    certain epochs.\n",
    "    \"\"\"\n",
    "    def __init__(self, patience=3, min_delta=1e-6):\n",
    "        \"\"\"\n",
    "        :param patience: how many epochs to wait before stopping when loss is\n",
    "               not improving\n",
    "        :param min_delta: minimum difference between new loss and old loss for\n",
    "               new loss to be considered as an improvement\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "        \n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss == None:\n",
    "            self.best_loss = val_loss\n",
    "        elif self.best_loss - val_loss > self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            # reset counter if validation loss improves\n",
    "            self.counter = 0\n",
    "        elif self.best_loss - val_loss < self.min_delta:\n",
    "            self.counter += 1\n",
    "            print(f\"INFO: Early stopping counter {self.counter} of {self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                print('INFO: Early stopping')\n",
    "                self.early_stop = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a049a07f-de50-4ac9-b9e1-f33b3bec289b",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94034ba3-b4e2-44ec-81e4-2afdc10a5b8d",
   "metadata": {},
   "source": [
    "###### We don't use kfold for now, simply a basic train_test_split to get a baseline of our performances. split_train_test_folds is our utils function to create split using folds, so it is left unused for the moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ed335a-620d-484e-a74c-cf28144a54cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test_folds(idx_folds):\n",
    "    \"\"\"\n",
    "    Turn a list of folds indexes into a list of train and val indexes.\n",
    "    \"\"\"\n",
    "    folds = []\n",
    "    N_folds = len(idx_folds)\n",
    "    for idx in range(N_folds):\n",
    "        train_folds = set(range(N_folds)) - {idx}\n",
    "        idx_trains = [idx for fold in train_folds for idx in idx_folds[fold]]\n",
    "        idx_vals = idx_folds[idx]\n",
    "        folds.append((idx_trains, idx_vals))\n",
    "        \n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb0dfc5-4341-42b8-9423-4b0112c5b7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(X, Y, model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    Y_hat = model(X)\n",
    "    batch_loss = loss_fn(Y_hat, Y)\n",
    "    batch_loss.backward()\n",
    "    optimizer.step()\n",
    "    Y_hat = Y_hat.detach().float().cpu().numpy()\n",
    "    \n",
    "    return Y_hat, batch_loss.item()\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def compute_val_loss(X, Y, model, loss_fn):\n",
    "    model.eval()\n",
    "    Y_hat = model(X)\n",
    "    batch_loss = loss_fn(Y_hat, Y)\n",
    "    Y_hat = Y_hat.detach().float().cpu().numpy()\n",
    "    \n",
    "    return Y_hat, batch_loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb1672c-bba3-4871-bd78-ba2323c2f012",
   "metadata": {},
   "source": [
    "###### We only use train_model at the moment, not train_folds to get our baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3214314-fee6-4eb8-bfd8-6630a725d88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_folds(df, folds):\n",
    "    for idx_fold, (idx_trains, idx_vals) in enumerate(folds, 1):\n",
    "        print(f\" # Fold {idx_fold}/{len(folds)}\")\n",
    "        time_start = time()\n",
    "        df_train, df_val = df.iloc[idx_trains], df.iloc[idx_vals]\n",
    "        _, _, dl_train, dl_val, _ = get_data(df_train, df_val)\n",
    "        train_model(dl_train, dl_val, idx_fold)\n",
    "        \n",
    "        print(\n",
    "            f\" # Fold {idx_fold}/{len(folds)} finished\"\n",
    "            f\", took {time() - time_start:.2f}s\"\n",
    "        )\n",
    "    \n",
    "        \n",
    "def train_model(dl_train, dl_val, idx_fold):\n",
    "    model, optimizer, loss_fn = get_model()\n",
    "    lr_scheduler = LRScheduler(optimizer)\n",
    "    early_stopping = EarlyStopping()\n",
    "\n",
    "    loss_train, loss_val = [], []\n",
    "    score_train, score_val = [], []\n",
    "\n",
    "    Y_hat_val = None\n",
    "    best_loss_val = np.inf\n",
    "\n",
    "    epochs = 20\n",
    "    for idx in range(epochs):\n",
    "        loss_train_epoch, loss_val_epoch = [], []\n",
    "        Y_hat_train_epoch, Y_hat_val_epoch = [], []\n",
    "        Y_train_epoch, Y_val_epoch = [], []\n",
    "\n",
    "        for X, Y in tqdm(dl_train, leave=False):\n",
    "            Y_hat, batch_loss = train_batch(X, Y, model, loss_fn, optimizer)\n",
    "            loss_train_epoch.append(batch_loss)\n",
    "            Y_hat_train_epoch.extend(Y_hat)\n",
    "            Y_train_epoch.extend(Y.detach().float().cpu().numpy())\n",
    "\n",
    "        for X, Y in tqdm(dl_val, leave=False):\n",
    "            Y_hat, batch_loss = compute_val_loss(X, Y, model, loss_fn)\n",
    "            loss_val_epoch.append(batch_loss)\n",
    "            Y_hat_val_epoch.extend(Y_hat)\n",
    "            Y_val_epoch.extend(Y.detach().float().cpu().numpy())\n",
    "                \n",
    "        avg_loss_train = np.mean(loss_train_epoch)\n",
    "        avg_loss_val = np.mean(loss_val_epoch)\n",
    "\n",
    "        Y_hat_train_epoch = np.array(Y_hat_train_epoch)\n",
    "        Y_hat_val_epoch = np.array(Y_hat_val_epoch)\n",
    "        Y_thresh_train_epoch = (Y_hat_train_epoch > .2).astype(float)\n",
    "        Y_thresh_val_epoch = (Y_hat_val_epoch > .2).astype(float)\n",
    "        Y_train_epoch = np.array(Y_train_epoch)\n",
    "        Y_val_epoch = np.array(Y_val_epoch)\n",
    "        \n",
    "        score_train_epoch = fbeta_score(Y_train_epoch, Y_thresh_train_epoch, beta=2, average=\"samples\")\n",
    "        score_val_epoch = fbeta_score(Y_val_epoch, Y_thresh_val_epoch, beta=2, average=\"samples\")\n",
    "               \n",
    "        # saving values for debugging\n",
    "        if avg_loss_val < best_loss_val:\n",
    "            best_loss_val = avg_loss_val\n",
    "            Y_hat_val = Y_hat_val_epoch\n",
    "            Y_thresh_val = Y_thresh_val_epoch\n",
    "            Y_val = Y_val_epoch\n",
    "            \n",
    "        \n",
    "        loss_train.append(avg_loss_train)\n",
    "        loss_val.append(avg_loss_val)\n",
    "        score_train.append(score_train_epoch)\n",
    "        score_val.append(score_val_epoch)\n",
    "\n",
    "        print(\n",
    "            f\"epoch: {idx}/{epochs} -- train loss: {avg_loss_train}, \" \\\n",
    "            f\"val loss: {avg_loss_val}\" \\\n",
    "            f\" -- train fbeta_score: {score_train_epoch}, \" \\\n",
    "            f\"val fbeta_score: {score_val_epoch}\"\n",
    "        )\n",
    "        \n",
    "        lr_scheduler(avg_loss_val)\n",
    "        early_stopping(avg_loss_val)\n",
    "        if early_stopping.early_stop:\n",
    "            break\n",
    "\n",
    "    train_results = {\n",
    "        \"loss_train\": loss_train,\n",
    "        \"loss_val\": loss_val,\n",
    "        \"score_train\": score_train,\n",
    "        \"score_val\": score_val,\n",
    "        \"Y_hat_val\": Y_hat_val,\n",
    "        \"Y_thresh_val\": Y_thresh_val,\n",
    "        \"Y_val\": Y_val,\n",
    "    }\n",
    "        \n",
    "    torch.save(model, f\"resnet18_fold{idx_fold}.pth\")\n",
    "    pickle.dump(train_results, open(f\"train_results_fold{idx_fold}.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef85b42-c904-4b01-876e-9d1d965efd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_val = train_test_split(df_class, test_size=.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f361eb-f224-44b5-9f8d-337c469d6758",
   "metadata": {},
   "outputs": [],
   "source": [
    "for rare_class in RARE_CLASSES:\n",
    "    total_train = df_train.loc[df_train.tags.str.contains(rare_class)].shape[0]\n",
    "    total_val = df_val.loc[df_val.tags.str.contains(rare_class)].shape[0]\n",
    "    print(f\"train {rare_class}: {100 * total_train / df_train.shape[0]:.4f}% ({total_train})\")\n",
    "    print(f\"val {rare_class}: {100 * total_val / df_val.shape[0]:.4f}% ({total_val})\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f5b99b-89aa-48ea-b274-ef3104a9fccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train, ds_val, dl_train, dl_val, encoder = get_data(df_train, df_val)\n",
    "train_model(dl_train, dl_val, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfcbf85-abc6-433d-ac27-cb2c9055e54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"resnet18_fold0.pth\")\n",
    "train_results = pickle.load(open(\"train_results_fold0.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4396f597-af36-4980-bb36-903c18f74052",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_train = train_results[\"loss_train\"]\n",
    "loss_val = train_results[\"loss_val\"]\n",
    "score_train = train_results[\"score_train\"]\n",
    "score_val = train_results[\"score_val\"]\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=(\"Loss\", \"Fbeta scores\"))\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=list(range(len(loss_train))),\n",
    "        y=loss_train,\n",
    "        name=\"loss_train\",\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=list(range(len(loss_val))),\n",
    "        y=loss_val,\n",
    "        name=\"loss_val\",\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=list(range(len(score_train))),\n",
    "        y=score_train,\n",
    "        name=\"score_train\",\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=list(range(len(score_val))),\n",
    "        y=score_val,\n",
    "        name=\"score_val\",\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5902f296-3986-414f-a0e7-400ddbe7752c",
   "metadata": {},
   "source": [
    "###### There is a slight overfitting starting at the 3rd epoch, although the performances don't improve much at the beginning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c910e1-6ff3-4856-aa46-0b449a971368",
   "metadata": {},
   "source": [
    "#### Understanding results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefc2dc2-765d-47e8-8a2c-27d50e4e8316",
   "metadata": {},
   "source": [
    "##### Marginal proba\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb5fbf2-4706-4a5a-8f12-25e997be0636",
   "metadata": {},
   "source": [
    "###### Let display the average of our Y_hat prediction proba, when the truth is Y = 1 or Y = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23551a25-c54c-41b8-acba-d457b6c5d850",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hat_val = np.array(train_results[\"Y_hat_val\"])\n",
    "Y_val = np.array(train_results[\"Y_val\"])\n",
    "\n",
    "pos_probas, neg_probas = [], []\n",
    "for class_, idx in encoder._cached_dict.items():\n",
    "    pos_probas.append(Y_hat_val[np.where(Y_val[:, idx] != 0), idx].mean())\n",
    "    neg_probas.append(Y_hat_val[np.where(Y_val[:, idx] == 0), idx].mean())\n",
    "go.Figure([\n",
    "    go.Bar(x=list(encoder._cached_dict), y=pos_probas, name=\"Y_hat proba | Y = 1\"),\n",
    "    go.Bar(x=list(encoder._cached_dict), y=neg_probas, name=\"Y_hat proba | Y = 0\")\n",
    "]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28067e89-992e-45a9-87d1-fe6c4de59212",
   "metadata": {},
   "source": [
    "###### Nice. We see that default thresholding at .2 might not always work. So we need to define the best threshold for each individual classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6481b3-ca6e-4988-8d1a-64957901161f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_thresholds(Y_hat, Y):\n",
    "    N_tags = Y.shape[1]\n",
    "    best_threshs = [0.2] * N_tags\n",
    "    resolution = 100\n",
    "    for jdx in tqdm(range(N_tags)):\n",
    "        best_score = 0\n",
    "        #threshs = np.zeros_like(best_threshs)\n",
    "        threshs = best_threshs.copy()\n",
    "        for kdx in range(resolution):\n",
    "            kdx /= resolution\n",
    "            threshs[jdx] = kdx\n",
    "            Y_hat_thresh = (Y_hat > threshs).astype(float)\n",
    "            score = fbeta_score(Y, Y_hat_thresh, beta=2, average=\"samples\")\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_threshs[jdx] = kdx\n",
    "    \n",
    "    global_best_score = fbeta_score(Y, (Y_hat > best_threshs).astype(float), beta=2, average=\"samples\")\n",
    "    print(f\"threshs: {best_threshs} -- best score: {global_best_score}\")\n",
    "    \n",
    "    return best_threshs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f7d8a9-7c44-4769-9a41-76aa0d54c389",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshs = find_best_thresholds(Y_hat_val, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988c95ab-71b1-4eec-b7c1-309b5ac33bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_scores = {}\n",
    "classes = encoder.classes_\n",
    "for jdx in range(Y_val.shape[1]):\n",
    "    y_val = Y_val[:, jdx].ravel()\n",
    "    y_hat_val = (Y_hat_val[:, jdx].ravel() > threshs[jdx]).astype(float)\n",
    "    score = fbeta_score(y_val, y_hat_val, beta=2)\n",
    "    class_scores[classes[jdx]] = round(score, 4)\n",
    "\n",
    "df_score = pd.DataFrame(dict(\n",
    "    label=list(class_scores.keys()), score=list(class_scores.values()),\n",
    ")).sort_values(\"score\", ascending=False)\n",
    "fig = px.bar(df_score, x=\"label\", y=\"score\", color=\"score\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca48473b-96da-4491-9971-9db8cfb90fcd",
   "metadata": {},
   "source": [
    "#### Confusion matrixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8a8781-b2a3-4129-816d-98ceed2decca",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(cols=5, rows=4)\n",
    "for jdx in range(Y_val.shape[1]):\n",
    "    y_val = Y_val[:, jdx].ravel()\n",
    "    y_hat_val = (Y_hat_val[:, jdx].ravel() > threshs[jdx]).astype(float)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_val, y_hat_val).ravel()\n",
    "    mat = np.array([[fn, tn], [tp, fp]])\n",
    "    col = jdx // 4+1\n",
    "    row = jdx % 4+1\n",
    "    fig.add_trace(\n",
    "        go.Heatmap(\n",
    "            z=mat, text=[[f\"fn: {fn}\", f\"tn: {tn}\"], [f\"tp: {tp}\", f\"fp: {fp}\"]], \n",
    "            texttemplate=\"%{text}\", colorscale='Viridis', name=encoder.classes_[jdx],\n",
    "            showscale=False\n",
    "        ),\n",
    "        col=col, row=row, \n",
    "    )\n",
    "    fig.update_xaxes(title=encoder.classes_[jdx], showticklabels=False, row=row, col=col)\n",
    "    fig.update_yaxes(showticklabels=False, row=row, col=col)\n",
    "    \n",
    "\n",
    "fig.update_layout(\n",
    "    width=1200, height=800, title=\"Confusion matrices\", \n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a59af7-f508-4b74-82b1-9cead854e3e2",
   "metadata": {},
   "source": [
    "###### slash_burn and blowdown scores contains more false negative (fn) than false positive (fp). However, fbeta score is more sensitive to fp than fn by design. Because we choose to shuffle our dataset in our dataloader, we can't display the original image of these fp and fn. That's an issue of our implementation. So to further analysis, we might add an index inside our output of the getitem and collate_fn methods of our Dataset class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2659005-2841-4826-9ded-132ae24f7601",
   "metadata": {},
   "source": [
    "#### Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2731d3-b839-47be-8995-daed75a4710a",
   "metadata": {},
   "source": [
    "###### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c289d3e4-1c33-46a1-9563-03522a0ea27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo $(ls ../input/planets-dataset/planet/planet/test-jpg | wc -l) + $(ls ../input/planets-dataset/test-jpg-additional/test-jpg-additional | wc -l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97bd66b-3e09-4818-8c49-be82bf68062f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_data():\n",
    "    path_test_table = \"../input/planets-dataset/planet/planet\"\n",
    "    path_test_file_1 = \"../input/planets-dataset/planet/planet/test-jpg\"\n",
    "    path_test_file_2 = \"../input/planets-dataset/test-jpg-additional/test-jpg-additional\"\n",
    "    file_count = len(os.listdir(path_test_file_1)) + len(os.listdir(path_test_file_2))\n",
    "    df_test = pd.read_csv(os.path.join(path_test_table, \"sample_submission.csv\"))\n",
    "    \n",
    "    assert df_test.shape[0] == file_count # sanity check\n",
    "    \n",
    "    ohe_tags_test = np.zeros((df_test.shape[0], 17))\n",
    "    _, transform_val = get_transforms()\n",
    "    ds_test = AmazonDataset(df_test, ohe_tags_test, transform_val, path=[path_test_file_1, path_test_file_2])\n",
    "    dl_test = DataLoader(\n",
    "        ds_test, shuffle=False, batch_size=32, collate_fn=ds_test.collate_fn\n",
    "    )\n",
    "    \n",
    "    return dl_test, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc29577c-1f03-476f-af28-c30ede009f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def batch_predict(model, X):\n",
    "    model.eval()\n",
    "    Y = model(X)\n",
    "    return Y.detach().float().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458189ee-d716-453a-9948-3a33e646fbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_test, df_test = get_test_data()\n",
    "\n",
    "Y_hat_test = []\n",
    "for X, _ in tqdm(dl_test):\n",
    "    Y_hat_test_batch = batch_predict(model, X)        \n",
    "    Y_hat_test.extend((Y_hat_test_batch > threshs).astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db5c409-491c-45c4-8088-b8f5a366ef18",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hat_test_inv = encoder.inverse_transform(np.array(Y_hat_test))\n",
    "test_tags = []\n",
    "for row in Y_hat_test_inv:\n",
    "    tags = \" \".join(row)\n",
    "    test_tags.append(tags)\n",
    "\n",
    "df_test[\"tags\"] = test_tags\n",
    "df_test.to_csv(\"my_sample_submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
